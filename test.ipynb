import torch
import torch.nn.functional as F
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
from torchsummary import summary
import time
import numpy as np
import matplotlib.pyplot as plt
NUM_EPOCHS = 10
BATCH_SIZE = 4
LEARNING_RATE = 0.001

"""
transform = transforms.Compose([
        transforms.ToTensor(),
    transforms.Normalize((0.5,),(0.5,))
    ])
trainset = torchvision.datasets.FashionMNIST(root='./data_new', train=True, download=True, transform=transform)
testset = torchvision.datasets.FashionMNIST(root='./data_new', train=False, download=True, transform=transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)
testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)
"""
# ~~~~~~
import gzip
import struct
import numpy as np

def read_idx(filename):
    with gzip.open(filename, 'rb') as f:
        zero, data_type, dims = struct.unpack('>HBB', f.read(4))
        shape = tuple(struct.unpack('>I', f.read(4))[0] for d in range(dims))
        return np.frombuffer(f.read(), dtype=np.uint8).reshape(shape)

class CustomDataset(torch.utils.data.Dataset):
    def __init__(self, image_path, label_path, transform=None):
        self.imgs = read_idx(image_path)
        self.labels = read_idx(label_path)
        self.transform = transform

    def __len__(self):
        return len(self.imgs)

    def __getitem__(self, idx):
        image = self.imgs[idx]
        label = self.labels[idx]
        if self.transform:
            image = self.transform(image)
        return image, label

# 데이터셋 및 DataLoader 설정
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])

train_image_path = 'path/to/t10k-images-idx3-ubyte.gz'
train_label_path = 'path/to/t10k-labels-idx1-ubyte.gz'

trainset = CustomDataset(image_path=train_image_path, label_path=train_label_path, transform=transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)

# ~~~~~

classes = ['T-shirt', 'Trouser', 'Pullover','Dress','Coat','Sandal','Shirt','Sneaker','Bag', 'AnkleBoot']
for batch_1 in trainloader:
    batch = batch_1
    break
print(f"Image shape:{batch[0].shape}")
print(f"Label shape:{batch[1].shape}")
plt.figure(figsize=(12,10))
for i in range(batch[0].shape[0]):
    plt.subplot(1,4, i+1)
    plt.title(classes[batch[1][i]])
    plt.imshow(batch[0][i,0,:,:])
    plt.axis('off')
plt.show()
class LeNet(nn.Module):
    def __init__(self):
        super(LeNet, self).__init__()
        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)
        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)
        self.fc1 = nn.Linear(in_features=256, out_features=120)
        self.fc2 = nn.Linear(in_features=120, out_features=84)
        self.fc3 = nn.Linear(in_features=84, out_features=10)
    def forward(self, x):
        x = F.relu(self.conv1(x))
        x = F.max_pool2d(x, kernel_size=2)
        x = F.relu(self.conv2(x))
        x = F.max_pool2d(x, kernel_size=2)
        x = x.view(x.size(0), -1)
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x
net = LeNet()
print(net)
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
net = net.to(device)
print(net)
loss_fn = nn.CrossEntropyLoss()
optimizer = optim.SGD(net.parameters(), lr=LEARNING_RATE, momentum=0.9)
def calc_acc(loader):
    correct = 0
    total = 0
    for data in loader:
        inputs, labels = data[0].to(device), data[1].to(device)
        outputs = net(inputs)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()
    return ((100 * correct)/ total)
def training():
    epoch_loss = []
    train_acc = []
    test_acc = []
    for epoch in range(NUM_EPOCHS):
        running_loss = 0.0
        for i, data in enumerate(trainloader, 0):
            inputs, labels = data[0].to(device), data[1].to(device)
            optimizer.zero_grad()
            outputs = net(inputs)
            loss = loss_fn(outputs, labels)
            loss.backward()
            optimizer.step()
            running_loss += loss.item()
        epoch_loss.append(running_loss)
        train_acc.append(calc_acc(trainloader))
        test_acc.append(calc_acc(testloader))
        print('Epoch: %d of %d, Train Accuracy: %0.3f, Test Accuracy: %0.3f, Loss: %0.3f'
              % (epoch+1, NUM_EPOCHS, train_acc[epoch], test_acc[epoch], running_loss/15000))
    return epoch_loss, train_acc, test_acc   
start = time.time()
epoch_loss, train_acc, test_acc = training()
end = time.time()
print("%0.2f Minutes" %((end-start)/60))
plt.figure(figsize=(20,6))
plt.subplot(1,3,1)
plt.plot(epoch_loss)
plt.title("Loss")
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.subplot(1,3,2)
plt.plot(train_acc)
plt.title("Train Accuracy")
plt.xlabel('Epoch')
plt.ylabel('Train Accuracy')
plt.subplot(1,3,3)
plt.plot(test_acc)
plt.title("Test Accuracy")
plt.xlabel('Epoch')
plt.ylabel('Test Accuracy')
plt.show()
net.eval()
correct = 0
total = 0
misclassified_images = []
misclassified_labels = []
misclassified_preds = []
with torch.no_grad():
    for images, labels in testloader:
        outputs = net(images)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()
        mask = (predicted != labels)
        misclassified_images.extend(images[mask])
        misclassified_labels.extend(labels[mask])
        misclassified_preds.extend(predicted[mask])
accuracy = 100 * correct / total
print(f'Accuracy of Test dataset : {accuracy:.2f}%')
misclassified_counts = np.zeros(len(classes))
for label in misclassified_labels:
    misclassified_counts[label] += 1
most_misclassified_class = classes[np.argmax(misclassified_counts)]
print(f'Most misclassified Class: {most_misclassified_class}')
plt.figure(figsize=(15, 5))
for i in range(min(10, len(misclassified_images))):
    plt.subplot(2, 5, i+1)
    img = misclassified_images[i].numpy().transpose((1, 2, 0))
    plt.imshow(img)
    plt.title(f'Answer: {classes[misclassified_labels[i]]}\nPrediction: {classes[misclassified_preds[i]]}')
    plt.xticks([])
    plt.yticks([])
plt.tight_layout()
plt.show()
